library(OpenML)
library(DALEX)
library(OpenML)
install.packages("OpenML")
library(OpenML)
library("OpenML", lib.loc="~/R/x86_64-pc-linux-gnu-library/3.4")
detach("package:OpenML", unload=TRUE)
remove.packages("OpenML", lib="~/R/x86_64-pc-linux-gnu-library/3.4")
install.packages("OpenML")
remove.packages("curl", lib="~/R/x86_64-pc-linux-gnu-library/3.4")
install.packages("curl")
install.packages("curl")
install.packages("OpenML")
library(readr)
data_train <- read_csv("Desktop/data_train.csv")
View(data_train)
data<-data_train[1:100,]
library(dplyr)
View(data)
(3750901.5068+3770901.5068)/2
(-19268905.6133-19208905.6133)/2
data %>% mutate(is_closer=dist(rbind(c(x_entry,y_entry),c(3760902,-19238906))>dist(rbind(c(x_exit,y_exit),c(3760902,-19238906))))
)
data %>% mutate(is_closer=dist(rbind(c(x_entry,y_entry),c(3760902,-19238906))>dist(rbind(c(x_exit,y_exit),c(3760902,-19238906)))))
data %>% mutate(is_closer=dist(rbind(c(x_entry,y_entry),c(3760902,-19238906))>dist(rbind(c(x_exit,y_exit),c(3760902,-19238906))))) ->tmp
View(tmp)
data$y_exit<- -19238906
data$x_exit<- 3760902
data %>% mutate(is_closer=dist(rbind(c(x_entry,y_entry),c(3760902,-19238906))>dist(rbind(c(x_exit,y_exit),c(3760902,-19238906))))) ->tmp
View(tmp)
data %>% mutate(is_closer=dist(rbind(c(x_entry,y_entry),c(3760902,-19238906)))>dist(rbind(c(x_exit,y_exit),c(3760902,-19238906)))) ->tmp
View(tmp)
data<-data_train[1:100,]
data %>% mutate(is_closer=dist(rbind(c(x_entry,y_entry),c(3760902,-19238906)))>dist(rbind(c(x_exit,y_exit),c(3760902,-19238906)))) ->tmp
View(tmp)
data$y_exit<- -19238906
data$x_exit<- 3760902
data %>% mutate(is_closer=dist(rbind(c(x_entry,y_entry),c(3760902,-19238906)))>dist(rbind(c(x_exit,y_exit),c(3760902,-19238906)))) ->tmp
View(tmp)
?dist()
data %>% mutate(is_closer=dist(rbind(c(x_entry,y_entry),c(3760902,-19238906)))) ->tmp
View(tmp)
data<-data_train[1:100,]
data %>% mutate(is_closer=dist(rbind(c(x_entry,y_entry),c(3760902,-19238906)))) ->tmp
View(tmp)
View(data)
mean(is.numeric(data_train$vmean))
is.numeric(data_train$vmean)
data_train$vmean
is.na(data_train$vmean)
mean(is.na(data_train$vmean) | data$vmean=="NaN")
data$vmean=="NaN"
mean(data$vmean=="NaN")
mean(data$vmean=="NaN",na.rm = TRUE)
mean(is.na(data_train$vmean))
mean(is.na(data_train$vmean))*mean(data$vmean=="NaN",na.rm = TRUE)
mean(data$vmean=="NaN",na.rm = TRUE)/mean(is.na(data_train$vmean))
#>dist(rbind(c(x_exit,y_exit),c(3760902,-19238906)))
mean(data$vmean=="NaN",na.rm = TRUE)
mean(is.na(data_train$vmean))
(1-mean(is.na(data_train$vmean)))*mean(data$vmean=="NaN",na.rm = TRUE)
(1-mean(is.na(data_train$vmax)))*mean(data$vmax=="NaN",na.rm = TRUE)
(1-mean(is.na(data_train$vmin)))*mean(data$vmin=="NaN",na.rm = TRUE)
setwd("~/Desktop/2019L-WUM/Zadania_domowe/Zadanie_domowe_5/Olaf_Werner")
library(mlr)
set.seed(123, "L'Ecuyer")
library(mlr)
#sprawdzamy paczki
listLearners(check.packages = TRUE)
#robimy taska i learnera
classif_task = makeClassifTask(id = "task", data = train, target =dane$target.features)
dane<-Titanic
dane
Titanic
install.packages("titanic")
library(titanic)
titanic::titanic_train
library(readr)
train <- read_csv("titanic/kaggle-titanic-master/input/train.csv")
View(train)
#robimy taska i learnera
classif_task <- makeClassifTask(id = "task", data = train, target =)
#robimy taska i learnera
classif_task <- makeClassifTask(id = "task", data = train, target = "Survived")
-1:-2
train<-train[-1:-2]
length(unique(train$Ticket))
length(unique(train$Embarked))
length(unique(train$SibSp))
library(DataExplorer)
train <- read_csv("titanic/kaggle-titanic-master/input/train.csv")
train<-drop_columns(train,c("Name","PassengerId"))
View(train)
library(dplyr)
train[sapply(train, is.character)] <- lapply(train[sapply(train, is.character)],as.factor)
train[!is.na(train$Cabin),]
unique(train[!is.na(train$Cabin),]$Cabin)
length(unique(train[!is.na(train$Cabin),]$Cabin))
train$Survived<-as.factor(train$Survived)
View(train)
train$Survived
set.seed(123, "L'Ecuyer")
library(mlr)
library(readr)
library(DataExplorer)
library(dplyr)
train <- read_csv("titanic/kaggle-titanic-master/input/train.csv")
train<-drop_columns(train,c("Name","PassengerId"))
train[sapply(train, is.character)] <- lapply(train[sapply(train, is.character)],as.factor)
train$Survived<-as.factor(train$Survived)
#robimy taska i learnera
classif_task <- makeClassifTask(id = "task", data = train, target = "Survived")
classif_learner<-makeLearner("classif.rpart",predict.type = "prob")
#testy Acc, AUC, Specificity, Recall, Precision, F1
Rcuda<-list(f1=f1, acc=acc, auc=auc, tnr=tnr, tpr=tpr ,ppv=ppv)
measures<-intersect(listMeasures(classif_task),c("f1", "acc", "auc", "tnr", "tpr" ,"ppv"))
#testy Acc, AUC, Specificity, Recall, Precision, F1
cv <- makeResampleDesc("CV", iters = 5)
r <- resample(classif_learner, classif_task, cv,measures = list(acc,auc,tnr,tpr,ppv,f1))
r<-r$aggr
r
?rpart::plotcp()
?resample
install.packages("rpart.plot")
install.packages("rpart")
train(learner,task)
mlr::train(learner,task)
set.seed(123, "L'Ecuyer")
library(mlr)
library(readr)
library(DataExplorer)
library(dplyr)
train <- read_csv("titanic/kaggle-titanic-master/input/train.csv")
train<-drop_columns(train,c("Name","PassengerId"))
train[sapply(train, is.character)] <- lapply(train[sapply(train, is.character)],as.factor)
train$Survived<-as.factor(train$Survived)
#robimy taska i learnera
task <- makeClassifTask(id = "task", data = train, target = "Survived")
learner<-makeLearner("classif.rpart",predict.type = "prob")
mlr::train(learner,task)
tree<-mlr::train(learner,task)
View(tree)
plot(tree)
library(rpart)
?rpart
print(tree)
plot(tree)
plot(tree$learner)
plot(tree$learner.model)
library(rpart.plot)
plot(tree$learner.model)
plot(tree)
rpart.plot(tree)
rpart.plot(tree$learner)
rpart.plot(tree$learner.model)
train <- read_csv("titanic/kaggle-titanic-master/input/train.csv")
train<-drop_columns(train,c("Name","PassengerId"))
train[sapply(train, is.character)] <- lapply(train[sapply(train, is.character)],as.factor)
train$Survived<-as.factor(train$Survived)
train$Cabin<-as.factor(!is.na(train$Cabin))
as.logical(21)
train <- read_csv("titanic/kaggle-titanic-master/input/train.csv")
train<-drop_columns(train,c("Name","PassengerId"))
train[sapply(train, is.character)] <- lapply(train[sapply(train, is.character)],as.factor)
train$Survived<-as.factor(as.logical(train$Survived))
train$Cabin<-as.factor(!is.na(train$Cabin))
View(train)
unique(train$Ticket)
train <- read_csv("titanic/kaggle-titanic-master/input/train.csv")
train<-drop_columns(train,c("Name","PassengerId","Ticket"))
train[sapply(train, is.character)] <- lapply(train[sapply(train, is.character)],as.factor)
train$Survived<-as.factor(as.logical(train$Survived))
train$Cabin<-as.factor(!is.na(train$Cabin))
#robimy taska i learnera
task <- makeClassifTask(id = "task", data = train, target = "Survived")
learner<-makeLearner("classif.rpart",predict.type = "prob")
tree<-mlr::train(learner,task)
#testy Acc, AUC, Specificity, Recall, Precision, F1
cv <- makeResampleDesc("CV", iters = 5)
r <- resample(learner, task, cv,measures = list(acc,auc,tnr,tpr,ppv,f1))
r<-r$aggr
r
rpart.plot(tree$learner.model)
table(train$Survived)
library(DataExplorer)
library(dplyr)
set.seed(123, "L'Ecuyer")
library(mlr)
library(readr)
library(DataExplorer)
library(dplyr)
library(rpart)
library(rpart.plot)
train <- read_csv("titanic/kaggle-titanic-master/input/train.csv")
train<-drop_columns(train,c("Name","PassengerId","Ticket"))
train[sapply(train, is.character)] <- lapply(train[sapply(train, is.character)],as.factor)
train$Survived<-as.factor(as.logical(train$Survived))
train$Cabin<-as.factor(!is.na(train$Cabin))
#robimy taska i learnera
task <- makeClassifTask(id = "task", data = train, target = "Survived")
learner<-makeLearner("classif.rpart",predict.type = "prob")
setwd("~/Desktop/WUM_projekt1")
library(tidyverse)
library(dplyr)
library(FNN)
library(gbm)
library(mlr)
library(randomForest)
library(e1071)
library(ranger)
library(MASS)
library(DALEX)
library(xgboost)
library(DataExplorer)
heloc_ok<-read_csv("heloc_ok.csv")
View(heloc_ok)
heloc_ok<-heloc_ok[-1]
give_me_AUC<-function(train_set)
{
n<-ncol(train_set)-1;
cv <- makeResampleDesc("CV", iters = 5)
#Random Froest
task <- makeClassifTask(data = train_set, target = "RiskPerformance")
model_all_rf <- makeLearner("classif.randomForest",
predict.type = "prob",
ntree = 100)
auc_all_rf<-r <- resample(model_all_rf, task, cv,measures=list(acc))
AUC<-auc_all_rf$aggr
name<-"rf"
number_of_cols<-n
AUC
# SVM
model_all_svm <- makeLearner("classif.svm",
predict.type = "prob")
auc_all_svm<-resample(model_all_svm, task, cv,measures=list(acc))
AUC<-append(AUC, auc_all_svm$aggr)
name<-append(name, "svm")
number_of_cols<-append(n, n)
#rpart
model_all_rpart <- makeLearner("classif.rpart",
predict.type = "prob")
auc_all_rpart<-resample(model_all_rpart, task, cv,measures=list(acc))
AUC<-append(AUC, auc_all_rpart$aggr)
name<-append(name, "rpart")
number_of_cols<-append(n, n)
#qda
model_all_qda <- makeLearner("classif.qda",
predict.type = "prob")
auc_all_qda<-resample(model_all_qda, task, cv,measures=list(acc))
AUC<-append(AUC, auc_all_qda$aggr)
name<-append(name, "qda")
number_of_cols<-append(n, n)
#lda
model_all_lda <- makeLearner("classif.lda",
predict.type = "prob")
auc_all_lda<-resample(model_all_lda, task, cv,measures=list(acc))
AUC<-append(AUC, auc_all_lda$aggr)
name<-append(name, "lda")
number_of_cols<-append(n, n)
#naive Bayes
model_all_nb <- makeLearner("classif.naiveBayes",
predict.type = "prob")
auc_all_nb<-resample(model_all_nb, task, cv,measures=list(acc))
AUC<-append(AUC, auc_all_nb$aggr)
name<-append(name, "nb")
number_of_cols<-append(n, n)
A<-data.frame(AUC=AUC, Classifier=name, number_of_cols=number_of_cols)
}
score1<-give_me_AUC(heloc_ok)
View(score1)
setwd("~/Desktop/2019L-WUM/Zadania_domowe/Zadanie_domowe_5/Olaf_Werner")
set.seed(123, "L'Ecuyer")
library(mlr)
library(readr)
library(DataExplorer)
library(dplyr)
library(rpart)
library(rpart.plot)
train <- read_csv("titanic/kaggle-titanic-master/input/train.csv")
train<-drop_columns(train,c("Name","PassengerId","Ticket"))
train[sapply(train, is.character)] <- lapply(train[sapply(train, is.character)],as.factor)
train$Survived<-as.factor(as.logical(train$Survived))
train$Cabin<-as.factor(!is.na(train$Cabin))
#robimy taska i learnera
task <- makeClassifTask(id = "task", data = train, target = "Survived")
learner<-makeLearner("classif.rpart",predict.type = "prob")
tree<-mlr::train(learner,task)
#testy Acc, AUC, Specificity, Recall, Precision, F1
cv <- makeResampleDesc("CV", iters = 5)
r <- resample(learner, task, cv,measures = list(acc,auc,tnr,tpr,ppv,f1))
r$models
r$extract
r <- resample(learner, task, cv,extract = TRUE,measures = list(acc,auc,tnr,tpr,ppv,f1))
set.seed(123, "L'Ecuyer")
library(mlr)
library(readr)
library(DataExplorer)
library(dplyr)
library(rpart)
library(rpart.plot)
train <- read_csv("titanic/kaggle-titanic-master/input/train.csv")
train<-drop_columns(train,c("Name","PassengerId","Ticket"))
train[sapply(train, is.character)] <- lapply(train[sapply(train, is.character)],as.factor)
train$Survived<-as.factor(as.logical(train$Survived))
train$Cabin<-as.factor(!is.na(train$Cabin))
#robimy taska i learnera
task <- makeClassifTask(id = "task", data = train, target = "Survived")
learner_default<-makeLearner("classif.rpart",predict.type = "prob")
learner_default<-makeLearner("classif.rpart",predict.type = "prob")
getHyperPars(learner = learner_default)
getParamSet(learner_default)
#getParamSet(learner_default)
learner_article<-makeLearner("classif.rpart",predict.type = "prob",par.vals = list(cp=0.001,maxdepth=13,minbucket=12,minsplit=18))
#testy Acc, AUC, Specificity, Recall, Precision, F1
cv <- makeResampleDesc("CV", iters = 5)
r <- resample(learner_article, task, cv,measures = list(acc,auc,tnr,tpr,ppv,f1))
r<-r$aggr
r
#testy Acc, AUC, Specificity, Recall, Precision, F1
cv <- makeResampleDesc("CV", iters = 5)
r_article <- resample(learner_article, task, cv,measures = list(acc,auc,tnr,tpr,ppv,f1))
r_article<-r_article$aggr
r_article
r_default <- resample(learner_default, task, cv,measures = list(acc,auc,tnr,tpr,ppv,f1))
r_default<-r_default$aggr
r_default
tree<-mlr::train(learner_article,task)
rpart.plot(tree$learner.model)
print(tree)
?makeNumericParam
getParamSet(learner_default)
rpart_pars <- tuneParams(
makeLearner("classif.rpart",predict.type = "prob"),
subsetTask(makeClassifTask(id = "task", data = train, target = "Survived")),
resampling = cv5,
measures = mlr::auc,
par.set = makeParamSet(
makeNumericParam("cp",lower = 0,upper = 1),
makeDiscreteParam("maxdepth", values = 1:30),
makeDiscreteParam("minbucket", values = 1:40),
makeDiscreteParam("minsplit", values = 1:40)
),
control = makeTuneControlRandom(maxit = 200)
)
rpart_pars$learner
rpart_pars$control
rpart_pars$x
learner_random<-makeLearner("classif.rpart",predict.type = "prob",par.vals = rpart_pars$x)
?resample
#testy Acc, AUC, Specificity, Recall, Precision, F1
cv <- makeResampleDesc("CV", iters = 5)
r_article <- resample(learner_article, task, cv,measures = list(acc,auc,tnr,tpr,ppv,f1))
View(r_article)
#testy Acc, AUC, Specificity, Recall, Precision, F1
cv <- makeResampleDesc("CV", iters = 5)
r_article <- resample(learner_article, task, cv,measures = list(acc,auc,tnr,tpr,ppv,f1),extract = function(x){getLearnerModel(x)})
r_article$extract
rpart.plot(r_article$extract)
rpart.plot(r_article$extract[1])
rpart.plot(r_article$extract[[1]])
r_article$measures.test
r_article$measures.train
r_article$measures.test
r_article$measures.test$auc
which.max(r_article$measures.test$auc)
#testy Acc, AUC, Specificity, Recall, Precision, F1
cv <- makeResampleDesc("CV", iters = 5)
r_article <- resample(learner_article, task, cv,measures = list(acc,auc,tnr,tpr,ppv,f1),extract = function(x){getLearnerModel(x)},show.info = FALSE)
rpart.plot(r_article$extract[[which.max(r_article$measures.test$auc)]])
r_article$aggr
?tuneParams
library(knitr)
knitr::kable(rbind(r_article$aggr,r_default$aggr,r_random$aggr),row.names = c("article","default","random"))
r_article <- resample(learner_article, task, cv,measures = list(auc),extract = function(x){getLearnerModel(x)},show.info = FALSE)
#rpart.plot(r_article$extract[[which.max(r_article$measures.test$auc)]])
r_article$aggr
r_default <- resample(learner_default, task, cv,measures = list(auc),extract = function(x){getLearnerModel(x)},show.info = FALSE)
#rpart.plot(r_default$extract[[which.max(r_default$measures.test$auc)]])
r_default$aggr
r_random <- resample(learner_random, task, cv,measures = list(auc),extract = function(x){getLearnerModel(x)},show.info = FALSE)
#rpart.plot(r_random$extract[[which.max(r_random$measures.test$auc)]])
r_random$aggr
knitr::kable(rbind(r_article$aggr,r_default$aggr,r_random$aggr),row.names = c("article","default","random"))
rbind(r_article$aggr,r_default$aggr,r_random$aggr)
knitr::kable(rbind(r_article$aggr,r_default$aggr,r_random$aggr))
?kable()
podsumowanie<-rbind(r_article$aggr,r_default$aggr,r_random$aggr)
rownames(podsumowanie)<-c("article","default","random")
knitr::kable(podsumowanie,row.names = TRUE)
getParamSet(learner_default)
learner_information<-makeLearner("classif.rpart",predict.type = "prob",par.vals = list(parms = list(split = 'information')))
?rpart.plot
par(mfrow=c(1,2))
learner_information<-makeLearner("classif.rpart",predict.type = "prob",par.vals = list(parms = list(split = 'information')))
tree_default<-mlr::train(learner_default,task)
rpart.plot(tree_default$learner.model)
tree_information<-mlr::train(learner_information,task)
rpart.plot(tree_information$learner.model)
setwd("~/Desktop/chtg")
source("functions.R")
install.packages("igraph")
install.packages("igraph")
install.packages("igraph")
install.packages("igraph")
install.packages("igraph")
install.packages("igraph")
### example calls ----
graf <- make_weighted_line_graph(file_to_igraph("myciel3.col"))
source("functions.R")
### example calls ----
graf <- make_weighted_line_graph(file_to_igraph("myciel3.col"))
View(graf)
plot(induced_subgraph(graf, get_heaviest_vertice_neighborhood(graf)))
plot(get_subgraph_without_neighborhood(graf, 1))
ggraf2 <- get_subgraph_without_neighborhood(graf2, get_heaviest_vertex(graf2))
plot(ggraf2, vertex.label = V(ggraf2)$names, vertex.color = V(ggraf2)$weights)
igraph_demo()
igraph_demo(smallworld())
smallworld()
?smallworld
g <- sample_smallworld(1, 100, 5, 0.05)
plot(g)
### example calls ----
graf <- make_weighted_line_graph(file_to_igraph("myciel3.col"))
plot(induced_subgraph(graf, get_heaviest_vertice_neighborhood(graf)))
get_heaviest_vertice_neighborhood(graf)
plot(induced_subgraph(graf, get_heaviest_vertex_neighborhood(graf)))
plot(get_subgraph_without_neighborhood(graf, 1))
ggraf2 <- get_subgraph_without_neighborhood(graf2, get_heaviest_vertex(graf2))
ggraf2 <- get_subgraph_without_neighborhood(graf, get_heaviest_vertex(graf))
plot(ggraf2, vertex.label = V(ggraf2)$names, vertex.color = V(ggraf2)$weights)
setwd("~/Desktop/WUM_projekt1")
knitr::opts_chunk$set(echo = TRUE)
knitr::include_graphics("krzywa_git.png")
knitr::include_graphics("boxploty.png")
# Libraries
knitr::opts_chunk$set(echo = FALSE)
library(readr)
library(mlr)
library(ggplot2)
library(DALEX)
library(knitr)
# Wczytywanie datasetu
# readr::read_csv("final_dataset.csv", col_types = cols(
#   library = col_factor(),
#   model_name = col_factor(),
#   numberOfCategoricalFeatures = col_double(),
#   numberOfNumericalFeatures = col_double(),
#   meanUniqueNumericalValues = col_double(),
#   meanUniqueCategoricalValues = col_double(),
#   meanNumberMissing = col_double(),
#   number_of_instances = col_double(),
#   ACC = col_double()
# )) -> df
# Dataset preparation
# df <- df[!is.na(df$meanUniqueNumericalValues), ]
# df <- df[!is.na(df$meanUniqueCategoricalValues), ]
knitr::include_graphics("ROC.png")
knitr::opts_chunk$set(echo = FALSE,warning = FALSE)
library(readr)
library(mlr)
library(ggplot2)
library(DALEX)
library(knitr)
heloc_ok<-read_csv("heloc_ok.csv")
heloc_ok<-heloc_ok[-1]
heloc_ok$MaxDelqEver<-factor(heloc_ok$MaxDelqEver)
heloc_ok$MaxDelq2PublicRecLast12M<-factor(heloc_ok$MaxDelq2PublicRecLast12M)
heloc_ok<-mlr::createDummyFeatures(heloc_ok)
heloc_ok$RiskPerformance<-factor(heloc_ok$RiskPerformance)
heloc_dataset_v1 <- read_csv("heloc_dataset_v1.csv")
heloc_dataset_v1$RiskPerformance<-factor(heloc_dataset_v1$RiskPerformance)
task<- makeClassifTask(id = "task", data = heloc_dataset_v1, target ="RiskPerformance")
learner_rpart<-makeLearner("classif.randomForest",predict.type = "prob")
cv <- makeResampleDesc("CV", iters = 5)
test_rpart <- resample(learner_rpart, task, cv,measures = auc,show.info = FALSE)
print(test_rpart)
roc_r = generateThreshVsPerfData(test_rpart$pred, list(fpr, tpr), aggregate = TRUE)
roc_r = generateThreshVsPerfData(test_rpart$pred, list(fpr, tpr), aggregate = TRUE)
plotROCCurves(roc_r)
?plotROCCurves
roc_r
