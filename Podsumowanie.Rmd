---
title: "Wstęp do uczenia maszynowego - projekt nr 1"
author: "Joanna Gajewska & Olaf Werner & Bogdan Jastrzębski"
date: "April 14, 2019"
output: ioslides_presentation
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,warning = FALSE)
library(readr)
library(mlr)
library(ggplot2)
library(DALEX)
library(knitr)
heloc_ok<-read_csv("heloc_ok.csv")
heloc_ok<-heloc_ok[-1]
heloc_ok$MaxDelqEver<-factor(heloc_ok$MaxDelqEver)
heloc_ok$MaxDelq2PublicRecLast12M<-factor(heloc_ok$MaxDelq2PublicRecLast12M)
heloc_ok<-mlr::createDummyFeatures(heloc_ok)
heloc_ok$RiskPerformance<-factor(heloc_ok$RiskPerformance)
heloc_dataset_v1 <- read_csv("heloc_dataset_v1.csv")
heloc_dataset_v1$RiskPerformance<-factor(heloc_dataset_v1$RiskPerformance)
```

## Nasz zbiór danych i pierwsze dopasowanie
Na samym początku mieliśmy nieoczyszczony zbiór danych FICO zobaczmy jak dla niego to wszytko działało

```{r echo=FALSE }
task<- makeClassifTask(id = "task", data = heloc_dataset_v1, target ="RiskPerformance")
learner_rpart<-makeLearner("classif.randomForest",predict.type = "prob")
cv <- makeResampleDesc("CV", iters = 5)
test_rpart <- resample(learner_rpart, task, cv,measures = auc,show.info = FALSE)
print(test_rpart)
```

Pięć linii kodu i pięć minut roboty daje nam około 77% AUC

##Krzywa ROC
```{r}
roc_r = generateThreshVsPerfData(test_rpart$pred, list(fpr, tpr), aggregate = TRUE)
plotROCCurves(roc_r)
```

##Czyszczenie 
W ramach czyszczenia zamieniliśmy typy odpowiednich zmiennych, usunęliśmy puste wiersze, ale nadal masę braków danych, dlatego w zależności od flagi braku podstawialiśmy różne rzeczy, przede wszystkim zrobiliśmy imputacje używając knn i w miejsce braku dawaliśmy średnią z 5 najbardziej podobnych rekordów.

##EPIC KNN IMPUTATION!

```{r echo=TRUE}
# for(i in 1:nrow(heloc_unclean)) {
#   #print(i)
#   badcols <- which(heloc_unclean_knn[i,] %in% c(-9,-8,-7))
#   k <- FNN::knn(heloc_clean_knn[-badcols], heloc_unclean_knn[i,-badcols], cl=heloc_clean[[1]],
#                 k=5,algorithm="cover_tree")
#   indices <- attr(k, "nn.index")
#   heloc_clean_knn[indices[1,],] %>% summarise_at(names(heloc_clean_knn)[badcols],mean)->imput
#   heloc_unclean_knn[i,badcols]<-imput
# }
```

##Ostateczna ostateczność
W ostatniej prezentacji pokazaliśmy że wszystkie zmienne są dość ważne i pokazaliśmy że dla randomForest osiągane są najlepsze wyniki,
 postanowiliśmy więc je ztuningować i oto rezultaty
 
```{r echo=FALSE}
task<-makeClassifTask(id = "task", data = heloc_ok, target ="RiskPerformance")
learner_rf<-makeLearner("classif.randomForest",predict.type = "prob")
test_rf <- resample(learner_rf, task, cv,measures = auc,show.info = FALSE)
print(test_rf)
roc_r = generateThreshVsPerfData(test_rf$pred, list(fpr, tpr), aggregate = TRUE)
```
 
##WOW
```{r}
plotROCCurves(roc_r)
```

##Podsumowanie
Po wielu godzinach pracy związanej z czyszczeniem, tuningowaniem i ustalaniem najlepszego modelu otrzymujemy 79 AUC co daje nam zwrost 0 2%.

